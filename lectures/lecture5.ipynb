{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0fce9da",
   "metadata": {},
   "source": [
    "# Lecture 4: SQL for vizualization\n",
    "Gittu George, January 13 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320aa509",
   "metadata": {},
   "source": [
    "## Todays Agenda\n",
    "\n",
    "- Vizualization science\n",
    "- Steps on vizualization \n",
    "- SQL tricks for data prep\n",
    "- Views\n",
    "- Data Cleaning science\n",
    "\n",
    "```{margin}\n",
    "<img src = 'img/cleaning.png'>\n",
    "```\n",
    "```{margin}\n",
    "<img src = 'img/visual.png'>\n",
    "```\n",
    "\n",
    "## Learning objectives\n",
    "- You will understand what kinds of graphs are best applied to various “questions.”\n",
    "- You will understand how to construct SQL queries to pre-process data for efficient plotting\n",
    "- You will be able to work from question, to figure, to SQL query\n",
    "- Why Data Cleaning Matters\n",
    "- How to develop a data cleaning plan as part of a workflow\n",
    "- How to establish and understand data standards for various data types\n",
    "- How to encode data cleaning standards into a database structure\n",
    "\n",
    "\n",
    "## Introduction to visualization science\n",
    "You will be doing many data visualization in this course for your assignments and projects. When you think about it, what are the first things that come to your mind?\n",
    "\n",
    "- There are so many different graphs out there; which one should I use?\n",
    "- There are so many different graphing tools out there; which one should I use?\n",
    "- Should my plot be static or dynamic?\n",
    "\n",
    "Answers to these questions solely rely on the purpose of a graph ?? !!\n",
    "\n",
    "```{sidebar} “Graphics reveal data.” - Edward Tufte\n",
    "\n",
    "Edward Tufte is a data scientist who did a lot of groundbreaking work in the field of visualization. His [book from 1983](https://www.edwardtufte.com/tufte/books_vdqi), is still referred and sited by many recent(eg [this](https://medium.com/nightingale/improve-your-visualization-skills-using-tuftes-principles-of-graphical-design-3a0f40a53a2c) & [this](https://towardsdatascience.com/little-known-ways-to-make-your-data-visualization-awesome-890d71b6e365)) articles. From his book, we will be discussing some of the general principles that you need to keep in mind.\n",
    "\n",
    "```\n",
    "\n",
    "In general, graphs should;\n",
    "- Make large datasets coherent\n",
    "- Serve a reasonably clear purpose\n",
    "- Be closely integrated with descriptions of the dataset\n",
    "- Induce the viewer to think about substance\n",
    "\n",
    "\n",
    "### General Principles for vizualization \n",
    "\n",
    "- Show the data (fairly)\n",
    "\n",
    "    Ensure that the data represented does not exaggerate or obscure true patterns.\n",
    "    \n",
    "    <img src='img/employmentl4.png' width='80%'>\n",
    "\n",
    "<br>\n",
    "\n",
    "- Maximize data-ink ratio\n",
    "\n",
    "    Elements in your figure should represent data, rather than adornment (grid lines &cetera)\n",
    "    \n",
    "    <img src='img/chartjunk.png' width='80%'>\n",
    "\n",
    "<br>\n",
    "\n",
    "- Erase non-data ink\n",
    "\n",
    "    As much as possible, reduce clutter around the data itself.\n",
    "\n",
    "    <img src='img/ink.png' width ='80%'>\n",
    "\n",
    "<br>\n",
    "\n",
    "- Erase redundant data-ink\n",
    "\n",
    "    Remove (or deprioritize) data that doesn’t support the statements\n",
    "\n",
    "    <img src='img/redundant.png' width='50%'>\n",
    "\n",
    "<br>\n",
    "\n",
    "- Edit your figures as you would your text\n",
    "\n",
    "    Ask, is this legible? Does this represent what we need it to show?\n",
    "    - InkScape\n",
    "    - CorelDRAW\n",
    "    - AI\n",
    "\n",
    "## Steps on vizualization \n",
    "By now, we understand the science of visualization, but you have to keep in mind that graphical display is more than graphs. Here are how the steps will look like, and here I will be showing some SQL tricks and techniques that you can use.\n",
    "\n",
    "### Data Preparation\n",
    "- What are we trying to plot?\n",
    "    - More variables or facets within your data mean more visual variables.\n",
    "    - Make clear choices about categorical vs. continuous variables.\n",
    "    \n",
    "    <img src='img/bertin.png' width='80%'>\n",
    "    \n",
    "    Source : [Bertin. 1967. Semiology of Graphics.](https://www.historyofinformation.com/detail.php?id=3361)\n",
    "    \n",
    "***We will be discussing later some of the SQL tricks.***\n",
    "\n",
    "- Are we plotting the data only once or to be redrawn frequently? Is the data preparation complex?\n",
    "    - We can manage longer processing times if things are plotted only once.\n",
    "    - A complex query only needs to be run once.\n",
    "    If data is updated often, or the plot must be regenerated often, we need other solutions.\n",
    "\n",
    "***And that's why we want to know about views which we will discuss in detail later.*** \n",
    "    \n",
    "### Reproducible Workflows\n",
    "- Considerations In Plotting Decisions\n",
    "    - How much data are you trying to plot?\n",
    "    - How many “series”?\n",
    "- Volume of Data\n",
    "    - Static presentation\n",
    "    - Dynamic presentation\n",
    "\n",
    "```{important}\n",
    "Simplify your data first. \n",
    "- Can we aggregate by type, count?\n",
    "\n",
    "    use GROUP BY\n",
    "\n",
    "- Do we need to prepare data ahead of time?\n",
    "\n",
    "    That's WHY we need to create MATERIALIZED VIEW. \n",
    "    \n",
    "- Is the data likely to change?\n",
    "\n",
    "    That's WHY we need to create VIEW. \n",
    "```\n",
    "### Visual Representation\n",
    "\n",
    "What are we Representing? Here are the main categories\n",
    "\n",
    "- Numeric data\n",
    "    - Univariate;\n",
    "        Histogram, density plot: Count of observations.\n",
    "    - Multivariate, n = 2;\n",
    "        Scatter plots (x vs. y), bar plots (count of y at value x), boxplots (distribution of y at x)\n",
    "    - Multivariate, n = 2; one variable ordered\n",
    "        line graph (ordered x vs. y), connected scatterplot (ordered x vs. y)\n",
    "        As n increases, we can use other graphic elements (hue, symbol shape & size) to represent other dimensions of the data\n",
    "\n",
    "- Categorical Data\n",
    "    - Univariate (keyword list &cetera)\n",
    "        Barplot (count of terms), word cloud (ugh); pie or donut chart (ugh)\n",
    "    - Univariate, structured\n",
    "        Dendrogram (hierarchy of relationships)\n",
    "    - Categorical with Numeric\n",
    "        Variations on numeric, using an extra facet\n",
    "\n",
    "An amazing reference: [data-to-viz](https://www.data-to-viz.com/)\n",
    "- Represent data SIMPLY\n",
    "- More graphs, less clutter.\n",
    "- Less text on the screen (significant figures!!!!)\n",
    "- Highlight the key elements (use the alpha channel!)\n",
    "\n",
    "<img src='img/facets.png' width='90%'>\n",
    "\n",
    "## SQL tricks\n",
    "\n",
    "These SQL tricks help with the data preparation for generating the plots.\n",
    "\n",
    "- Group continuous variable using [CASE](https://www.postgresql.org/docs/8.4/functions-conditional.html):\n",
    "\n",
    "```\n",
    "SELECT varone,\n",
    "\tCASE WHEN vartwo < 5 THEN ‘Small’\n",
    "         WHEN vartwo < 10 THEN ‘Medium’\n",
    "         WHEN vartwo > 10 THEN ‘Big’\n",
    "    END,\n",
    "    varthree\n",
    "FROM table;  \n",
    "```\n",
    "\n",
    "<img src='img/table1.png' width='90%'>\n",
    "\n",
    "- Dealing with missing values using [COALESCE](https://www.postgresql.org/docs/8.1/functions-conditional.html)\n",
    "\n",
    "```\n",
    "SELECT varone, \n",
    "COALESCE(vartwo, 0)\n",
    "FROM table;\n",
    "```\n",
    "\n",
    "COALESCE is used to deal with potential NULL values. It saves you from dealing with it in Python & lets you clearly define how you deal with missing values.\n",
    "\n",
    "<img src='img/table2.png' width='90%'>\n",
    "\n",
    "- Changing plotting order:\n",
    "\n",
    "```\n",
    "SELECT varone,\n",
    "   vartwo,\n",
    "   varthree\n",
    "FROM table\n",
    "ORDER BY varone;\n",
    "```\n",
    "\n",
    "<img src='img/table3.png' width='90%'>\n",
    "\n",
    "- Changing plotting order with random:\n",
    "\n",
    "Using random() allows us to sort by a random value that is recalculated each time.\n",
    "\n",
    "```\n",
    "Changing order:\n",
    "SELECT varone,\n",
    "   vartwo,\n",
    "   varthree\n",
    "FROM table\n",
    "ORDER BY random();\n",
    "```\n",
    "\n",
    "<img src='img/table4.png' width='90%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ed3dec-6b78-434e-a317-338860ac4095",
   "metadata": {},
   "source": [
    "## Views\n",
    "\n",
    "Whether we want to use VIEWS depends on the plotting or querying frequency. For example, complex queries with changing data that will be run multiple times (or have varying “WHERE” statements) can use a VIEW.\n",
    "\n",
    "Check out how much time this query is taking to run. Before all that lets initiate the connection to the database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc60f875-dd47-4e1a-9d7f-9da998474cc2",
   "metadata": {},
   "source": [
    "```\n",
    "import os\n",
    "import psycopg2\n",
    "\n",
    "##Make sure you import and load your .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "conString = {'host':os.environ.get('DB_HOST'),\n",
    "             'dbname':os.environ.get('DB_NAME'),\n",
    "             'user':os.environ.get('DB_USER'),\n",
    "             'password':os.environ.get('DB_PASS'),\n",
    "             'port':os.environ.get('DB_PORT')}\n",
    "print(conString[\"port\"])\n",
    "conn = psycopg2.connect(**conString)\n",
    "cur = conn.cursor()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0c1d2b-a42d-4c13-8459-0672f891912d",
   "metadata": {},
   "source": [
    "```\n",
    "%%time\n",
    "query=\"\"\"SELECT tw.id, \n",
    "       unnest(regexp_matches(tw.text, '\\$[A-Z]+\\M', 'g')) AS substring\n",
    "FROM import.tweets AS tw;\"\"\"\n",
    "cur.execute(query)\n",
    "cur.fetchmany(5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5415237e-a9da-45f4-b792-ba36c5f3d34a",
   "metadata": {},
   "source": [
    "Let's create a view "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a53161e-0968-4e28-9294-4b7d3d6ffd89",
   "metadata": {},
   "source": [
    "```\n",
    "%%time\n",
    "query=\"\"\"CREATE OR REPLACE VIEW import.tickertweets AS\n",
    "SELECT tw.id, unnest(regexp_matches(tw.text, '\\$[A-Z]+\\M', 'g')) AS substring\n",
    "FROM import.tweets AS tw;\"\"\"\n",
    "cur.execute(query)\n",
    "conn.commit()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3fedad-acaf-4927-8507-c4ef71dbe520",
   "metadata": {},
   "source": [
    "Let's see the query time when we call it from the VIEW."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a999556-cf91-4f1d-b34c-a5b9a9348a2a",
   "metadata": {},
   "source": [
    "```\n",
    "%%time\n",
    "query=\"\"\"SELECT * FROM import.tickertweets;\"\"\"\n",
    "cur.execute(query)\n",
    "cur.fetchmany(5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0365c2ac-30d9-4064-8e44-1aa30746ea9e",
   "metadata": {},
   "source": [
    "So, a TABLE is stored data. A VIEW is a stored query. A VIEW’s query is stored to be cached (saved to memory) for faster retrieval and optimized for speed.\n",
    "\n",
    "Complex queries with fixed data that will be run multiple times (or have varying “WHERE” statement) can use a MATERIALIZED VIEW:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec2fd3d-3e1a-4cee-a6fe-d0749f7c7147",
   "metadata": {},
   "source": [
    "```\n",
    "%%time\n",
    "query=\"\"\"DROP MATERIALIZED VIEW import.tickertweetsmat CASCADE;\"\"\"\n",
    "cur.execute(query)\n",
    "conn.commit()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1de88d3-c4b0-4ea7-8180-92f70fca918d",
   "metadata": {},
   "source": [
    "```\n",
    "%%time\n",
    "query=\"\"\"CREATE MATERIALIZED VIEW import.tickertweetsmat AS\n",
    "SELECT tw.id, \n",
    "  unnest(regexp_matches(tw.text, '\\$[A-Z]+\\M', 'g')) AS substring\n",
    "FROM import.tweets AS tw;\"\"\"\n",
    "cur.execute(query)\n",
    "conn.commit()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f5462a-bdc5-4055-8490-a3b8dd8e7e2a",
   "metadata": {},
   "source": [
    "Let's see the query time when we call it from the VIEW."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2b3912-66db-4694-b249-66cc183bdc9a",
   "metadata": {},
   "source": [
    "```\n",
    "%%time\n",
    "query=\"\"\"SELECT * FROM import.tickertweetsmat;\"\"\"\n",
    "cur.execute(query)\n",
    "cur.fetchmany(5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a490e8-7455-4147-883b-3ba3d328f544",
   "metadata": {},
   "source": [
    "- A TABLE is stored data.  \n",
    "- A VIEW is a stored query.  \n",
    "- A MATERIALIZED VIEW is a query committed to stored data.\n",
    "\n",
    "When to use what?\n",
    "- Choose a table when the underlying data don’t change (except for INSERTs)\n",
    "- Choose a MATERIALIZED VIEW when the query is slow, and you can tolerate some lag between UPDATE/INSERTs and updated values.\n",
    "- Choose a VIEW when you reuse the query and want to simplify calling it.\n",
    "\n",
    "Check out these yourself?\n",
    "\n",
    "- How much time does it take to create a view vs. materialized view?\n",
    "- How much time does it take to query? You can use these queries to find that out.\n",
    "- How much space does it take? You can use these queries to find that out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22253f4b-b282-4464-8f88-682dba27f2b7",
   "metadata": {},
   "source": [
    "```\n",
    "%%time\n",
    "query=\"\"\"SELECT pg_size_pretty (pg_relation_size('import.tickertweets'));\"\"\"\n",
    "cur.execute(query)\n",
    "print(cur.fetchone())\n",
    "query=\"\"\"SELECT pg_size_pretty (pg_relation_size('import.tickertweetsmat'));\"\"\"\n",
    "cur.execute(query)\n",
    "print(cur.fetchone())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f1ef59",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "- Views can be an important tool in managing long-running queries for visualization (and for other purposes)\n",
    "- Tradeoffs exist with respect to storage space and the rate at which data needs to be refreshed.\n",
    "\n",
    "| Table                              | View             | Materialized View | SELECT Query     |\n",
    "|------------------------------------|------------------|-------------------|------------------|\n",
    "| High Disk Space                    | Low Disk Space   | High Disk Space   | Low Disk Space   |\n",
    "| Fast Read Time                     | Slower Read Time | Fast Read Time    | Slow Read Time   |\n",
    "| Fixed Values (cannot be refreshed) | Can be refreshed | Can be refreshed  | Always refreshed |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5df4ba4",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "<img src='img/BORING.png' width='90%'>\n",
    "```\n",
    "## Data Cleaning\n",
    "\n",
    "Before we get to visualization or the table, we need to think about data cleaning. This is considered very important yet tedious, where analysts spend most of their time.\n",
    "\n",
    "### Why Does Clean Data Matter?\n",
    "\n",
    "Dirty data impacts every part of business decision-making. Outliers, data gaps, misspellings, poorly structured data, incorrectly entered, invalid values, duplication.\n",
    "\n",
    "```{margin}\n",
    "“At the operational level, poor data leads directly to customer dissatisfaction, increased cost, and lowered employee job satisfaction. . . 8 - 12% of revenue may be consumed by bad data.”\n",
    "[TC Redman](https://dl.acm.org/doi/pdf/10.1145/269012.269025)\n",
    "```\n",
    "\n",
    "- Garbage in - Garbage out\n",
    "\n",
    "If you put dirty data in, then what you will be getting, as a result, will be dirty or of no use, or even worse, it can mislead you.\n",
    "\n",
    "- Time is money\n",
    "\n",
    "Suppose your data issues get addressed at the point when the data is initially consumed. In that case, there is a meager cost associated with it, but once data gets dispersed throughout the company with different project groups, it becomes harder to address as you want to bring this change across all departments. Then once you've started to make strategic decisions based on this data, it becomes very expensive to correct the data as you also want to deal with the consequences of bad strategy decisions.\n",
    "\n",
    "```{margin}\n",
    "50% — the amount of time that knowledge workers waste in hidden data factories, hunting for data, finding and correcting errors, and searching for confirmatory sources for data they don’t trust.”\n",
    "[Redman (2016) HBR](https://hbr.org/2016/09/bad-data-costs-the-u-s-3-trillion-per-year)\n",
    "```\n",
    "\n",
    "\n",
    "### Impacts with the dirty data \n",
    "\n",
    "```{margin}\n",
    "NASA's Mars Climate Orbiter was designed to study Mars from orbit and serve as a communications relay for the Mars Polar Lander and Deep Space probes. Unfortunately, the mission was unsuccessful due to a navigation error caused by a failure to translate English units to metric.\n",
    "[NASA](https://solarsystem.nasa.gov/missions/mars-climate-orbiter/in-depth/)\n",
    "```\n",
    "\n",
    "It can be broadly categorized into\n",
    "\n",
    "- Operational \n",
    "\n",
    "    - Customer service impacts (mismatched addresses)\n",
    "    - More costly to analyze data and produce insights\n",
    "\n",
    "- Strategic\n",
    "\n",
    "    - More difficult to set & execute a broad strategy\n",
    "    - More challenging to align needs in large organizations\n",
    "    \n",
    "\n",
    "\n",
    "### Where Does Dirty Data Come From & how to approach?\n",
    "\n",
    "It can come from anywhere. So don't just think that it had to do with the external data; sometimes, internal data that has been provided to you might be dirtier.\n",
    "\n",
    "<img src='img/dirtydata.png' width='75%'>\n",
    "\n",
    "```{note}\n",
    "Data Screening deals with finding errors (generally at data input or analysis)\n",
    "Data Cleaning fixes errors, reformats data following data acquisition.\n",
    "```\n",
    "Data Cleaning means having a plan\n",
    "- Any analysis you do will use some combination of internal and external data\n",
    "- You can expect that “finding”, “screening,” and “cleaning” data will take close to a majority of your time\n",
    "- You can expect that to costs of poor data management and cleaning can be significant in time and value\n",
    "- Beginning with a Data Cleaning Plan is perhaps the most critical stage of analysis.\n",
    "\n",
    "### Elements of a Data Cleaning Plan\n",
    "\n",
    "#### Dataset Provenance Metadata\n",
    "Assume you are a consumer and producer\n",
    "\n",
    "```{margin}\n",
    "Without provenance, consumers have no inherent way to trust the integrity and credibility of shared data. Data publishers, in turn, need to be aware of the needs of prospective consumer communities to know how much provenance detail is appropriate. \n",
    "[W3C Data On The Web Best Practices](https://www.w3.org/TR/dwbp/#provenance)\n",
    "```\n",
    "\n",
    "For Each Dataset (dataset level metadata):\n",
    "- Title\n",
    "- URI (source location\n",
    "- Keywords (if needed)\n",
    "- Publication Date\n",
    "- Publisher\n",
    "- Creator\n",
    "- Contact Point\n",
    "- Spatial Coverage\n",
    "- Temporal Coverage\n",
    "- Language\n",
    "- Date & Time Formats\n",
    "- Data Version\n",
    "- Access Date\n",
    "\n",
    "It can be formatted as plain text, YAML, JSON, or other\n",
    "W3C Data on the Web: [link](https://www.w3.org/TR/dwbp) \n",
    "\n",
    "#### Data Quality Documentation (pre-cleaning)\n",
    "\n",
    "- Completeness per row\n",
    "\n",
    "Do we have all the data we need in each table?\n",
    "\n",
    "- Syntactical Correctness\n",
    "\n",
    "Are all data in the expected & correct format?\n",
    "\n",
    "- Absence of Contradictions\n",
    "\n",
    "All data are in alignment with one another & with expectations.\n",
    "\n",
    "- Accuracy\n",
    "\n",
    "All data is up to date and accurate.\n",
    "\n",
    "- Absence of repetition\n",
    "\n",
    "Synonyms & overlapping values addressed; all entities unique\n",
    "Overlapping values & synonyms addressed; each entity is unique\n",
    "\n",
    "- Referential Integrity\n",
    "\n",
    "Required references and entities are complete.\n",
    "\n",
    "- Completeness\n",
    "\n",
    "All cross-sum products are complete (sum of product counts == total inventory count)\n",
    "\n",
    "- Normative consistency\n",
    "\n",
    "The naming and meaning of data is the same overall systems\n",
    "\n",
    "#### Data Cleaning Documentation\n",
    "- All steps (and the order of steps) should be preserved and documented.\n",
    "- All steps should be reproducible (within reason)\n",
    "- Reproducibility either directly (by executing a script directly) or indirectly (explaining the steps in a program)\n",
    "\n",
    "\n",
    "#### Data Quality Documentation (post-cleaning)\n",
    "#### Quality Assessment / Error Reporting Procedures\n",
    "- Clear documentation of quality assessment metrics (as above)\n",
    "- Clear documentation of how to report/address data issues.\n",
    "\n",
    "### Data Standards for Databases\n",
    "\n",
    "- [schema.org](https://schema.org)\n",
    "- [Microsoft Common Data Standard](https://github.com/microsoft/CDM)\n",
    "- [datastandards.directory](https://datastandards.directory/)\n",
    "- [W3 standards for dates](https://www.w3.org/TR/NOTE-datetime), [Blog post](https://www.iso.org/news/2017/02/Ref2164.html) about the most recent ISO 8601 standard update\n",
    "\n",
    "    - April 2, 1974\n",
    "    - 04-02-74\n",
    "    - 04/02/1974\n",
    "    - 4/2/74\n",
    "    - 19740402\n",
    "    - 04021974 - is this April 2 or February 4?\n",
    "    - 2 April 1974\n",
    "\n",
    "- [W3 standards for names](https://www.w3.org/International/questions/qa-personal-names)\n",
    "    - Don't think people have one name\n",
    "    - Don't think people’s names do not change\n",
    "    - Don't think people’s names have canonical order (First, Last)\n",
    "\n",
    "- Provide clear meaning for data elements\n",
    "  - Either separately or within the database (COMMENT ON ...)\n",
    "```\n",
    "COMMENT ON TABLE mytable IS 'This table is the table for my data.';\n",
    "COMMENT ON COLUMN my_table.my_column IS 'Employee ID number';\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
